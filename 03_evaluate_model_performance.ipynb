{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import sys; sys.path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multitest import multipletests as fdr\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load prediction accuracy data from optimised sex-independent and sex-specific models\n",
    "fc_bf = pd.read_csv('corr_bf.txt', header=None).values\n",
    "fc_bm = pd.read_csv('corr_bm.txt', header=None).values\n",
    "fc_mf = pd.read_csv('corr_mf.txt', header=None).values\n",
    "fc_mm = pd.read_csv('corr_mm.txt', header=None).values\n",
    "fc_ff = pd.read_csv('corr_ff.txt', header=None).values\n",
    "fc_fm = pd.read_csv('corr_fm.txt', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load prediction accuracy data from null models\n",
    "null_fc_bf = np.median(pd.read_csv('corr_bf.txt', header=None).values, axis=0)\n",
    "null_fc_bm = np.median(pd.read_csv('corr_bm.txt', header=None).values, axis=0)\n",
    "null_fc_mf = np.median(pd.read_csv('corr_mf.txt', header=None).values, axis=0)\n",
    "null_fc_mm = np.median(pd.read_csv('corr_mm.txt', header=None).values, axis=0)\n",
    "null_fc_ff = np.median(pd.read_csv('corr_ff.txt', header=None).values, axis=0)\n",
    "null_fc_fm = np.median(pd.read_csv('corr_fm.txt', header=None).values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names of all the cognitive variables \n",
    "cognition = ['Crystal','Fluid','Total','PicVocab','Reading','Flanker','CardSort','PicSeq','ListSort','ProcSpeed']\n",
    "\n",
    "#create a data frame for each cognitive variable with results from all the models \n",
    "crystal = pd.DataFrame({'bf' : fc_bf[:,0], \n",
    "                     'bm' : fc_bm[:,0], \n",
    "                     'mf' : fc_mf[:,0], \n",
    "                     'mm' : fc_mm[:,0], \n",
    "                     'ff' : fc_ff[:,0], \n",
    "                     'fm' : fc_fm[:,0]}) \n",
    "\n",
    "fluid = pd.DataFrame({'bf' : fc_bf[:,1], \n",
    "                     'bm' : fc_bm[:,1], \n",
    "                     'mf' : fc_mf[:,1], \n",
    "                     'mm' : fc_mm[:,1], \n",
    "                     'ff' : fc_ff[:,1], \n",
    "                     'fm' : fc_fm[:,1]}) \n",
    "\n",
    "total = pd.DataFrame({'bf' : fc_bf[:,2], \n",
    "                     'bm' : fc_bm[:,2], \n",
    "                     'mf' : fc_mf[:,2], \n",
    "                     'mm' : fc_mm[:,2], \n",
    "                     'ff' : fc_ff[:,2], \n",
    "                     'fm' : fc_fm[:,2]}) \n",
    "\n",
    "picvocab = pd.DataFrame({'bf' : fc_bf[:,3], \n",
    "                     'bm' : fc_bm[:,3], \n",
    "                     'mf' : fc_mf[:,3], \n",
    "                     'mm' : fc_mm[:,3], \n",
    "                     'ff' : fc_ff[:,3], \n",
    "                     'fm' : fc_fm[:,3]}) \n",
    "\n",
    "reading = pd.DataFrame({'bf' : fc_bf[:,4], \n",
    "                     'bm' : fc_bm[:,4], \n",
    "                     'mf' : fc_mf[:,4], \n",
    "                     'mm' : fc_mm[:,4], \n",
    "                     'ff' : fc_ff[:,4], \n",
    "                     'fm' : fc_fm[:,4]}) \n",
    "\n",
    "flanker = pd.DataFrame({'bf' : fc_bf[:,5], \n",
    "                     'bm' : fc_bm[:,5], \n",
    "                     'mf' : fc_mf[:,5], \n",
    "                     'mm' : fc_mm[:,5], \n",
    "                     'ff' : fc_ff[:,5], \n",
    "                     'fm' : fc_fm[:,5]}) \n",
    "\n",
    "\n",
    "cardsort = pd.DataFrame({'bf' : fc_bf[:,6], \n",
    "                     'bm' : fc_bm[:,6], \n",
    "                     'mf' : fc_mf[:,6], \n",
    "                     'mm' : fc_mm[:,6], \n",
    "                     'ff' : fc_ff[:,6], \n",
    "                     'fm' : fc_fm[:,6]}) \n",
    "\n",
    "picseq = pd.DataFrame({'bf' : fc_bf[:,7], \n",
    "                     'bm' : fc_bm[:,7], \n",
    "                     'mf' : fc_mf[:,7], \n",
    "                     'mm' : fc_mm[:,7], \n",
    "                     'ff' : fc_ff[:,7], \n",
    "                     'fm' : fc_fm[:,7]}) \n",
    "\n",
    "listsort = pd.DataFrame({'bf' : fc_bf[:,8], \n",
    "                     'bm' : fc_bm[:,8], \n",
    "                     'mf' : fc_mf[:,8], \n",
    "                     'mm' : fc_mm[:,8], \n",
    "                     'ff' : fc_ff[:,8], \n",
    "                     'fm' : fc_fm[:,8]}) \n",
    "\n",
    "procspeed = pd.DataFrame({'bf' : fc_bf[:,9], \n",
    "                     'bm' : fc_bm[:,9], \n",
    "                     'mf' : fc_mf[:,9], \n",
    "                     'mm' : fc_mm[:,9], \n",
    "                     'ff' : fc_ff[:,9], \n",
    "                     'fm' : fc_fm[:,9]}) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to evaluate whether each model is better than the null\n",
    "def get_null_p(x,null):\n",
    "    pval = 1-np.mean(x-null>=0)\n",
    "    \n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to evaluate whether a pair of models are different in performance\n",
    "def get_exact_p(x,y):\n",
    "    pval = 2*np.min([np.mean(x-y>=0), np.mean(x-y<=0)])\n",
    "    \n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of crystallised abilities against null\n",
    "crystal_p_fc_bf = get_null_p(fc_bf[:,0], null_fc_bf[0])\n",
    "crystal_p_fc_bm = get_null_p(fc_bm[:,0], null_fc_bm[0])\n",
    "crystal_p_fc_mf = get_null_p(fc_mf[:,0], null_fc_mf[0])\n",
    "crystal_p_fc_mm = get_null_p(fc_mm[:,0], null_fc_mm[0])\n",
    "crystal_p_fc_ff = get_null_p(fc_ff[:,0], null_fc_ff[0])\n",
    "crystal_p_fc_fm = get_null_p(fc_fm[:,0], null_fc_fm[0])\n",
    "\n",
    "\n",
    "crystal_pvals = [crystal_p_fc_bf, crystal_p_fc_bm, \n",
    "                 crystal_p_fc_mf, crystal_p_fc_mm,\n",
    "                 crystal_p_fc_ff, crystal_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of fluid abilities against null\n",
    "fluid_p_fc_bf = get_null_p(fc_bf[:,1], null_fc_bf[1])\n",
    "fluid_p_fc_bm = get_null_p(fc_bm[:,1], null_fc_bm[1])\n",
    "fluid_p_fc_mf = get_null_p(fc_mf[:,1], null_fc_mf[1])\n",
    "fluid_p_fc_mm = get_null_p(fc_mm[:,1], null_fc_mm[1])\n",
    "fluid_p_fc_ff = get_null_p(fc_ff[:,1], null_fc_ff[1])\n",
    "fluid_p_fc_fm = get_null_p(fc_fm[:,1], null_fc_fm[1])\n",
    "\n",
    "\n",
    "fluid_pvals = [fluid_p_fc_bf, fluid_p_fc_bm, \n",
    "                 fluid_p_fc_mf, fluid_p_fc_mm,\n",
    "                 fluid_p_fc_ff, fluid_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of total abilities against null\n",
    "total_p_fc_bf = get_null_p(fc_bf[:,2], null_fc_bf[2])\n",
    "total_p_fc_bm = get_null_p(fc_bm[:,2], null_fc_bm[2])\n",
    "total_p_fc_mf = get_null_p(fc_mf[:,2], null_fc_mf[2])\n",
    "total_p_fc_mm = get_null_p(fc_mm[:,2], null_fc_mm[2])\n",
    "total_p_fc_ff = get_null_p(fc_ff[:,2], null_fc_ff[2])\n",
    "total_p_fc_fm = get_null_p(fc_fm[:,2], null_fc_fm[2])\n",
    "\n",
    "\n",
    "total_pvals = [total_p_fc_bf, total_p_fc_bm, \n",
    "                 total_p_fc_mf, total_p_fc_mm,\n",
    "                 total_p_fc_ff, total_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of pic vocab abilities against null\n",
    "picvocab_p_fc_bf = get_null_p(fc_bf[:,3], null_fc_bf[3])\n",
    "picvocab_p_fc_bm = get_null_p(fc_bm[:,3], null_fc_bm[3])\n",
    "picvocab_p_fc_mf = get_null_p(fc_mf[:,3], null_fc_mf[3])\n",
    "picvocab_p_fc_mm = get_null_p(fc_mm[:,3], null_fc_mm[3])\n",
    "picvocab_p_fc_ff = get_null_p(fc_ff[:,3], null_fc_ff[3])\n",
    "picvocab_p_fc_fm = get_null_p(fc_fm[:,3], null_fc_fm[3])\n",
    "\n",
    "\n",
    "picvocab_pvals = [picvocab_p_fc_bf, picvocab_p_fc_bm, \n",
    "                 picvocab_p_fc_mf, picvocab_p_fc_mm,\n",
    "                 picvocab_p_fc_ff, picvocab_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of reading abilities against null\n",
    "reading_p_fc_bf = get_null_p(fc_bf[:,4], null_fc_bf[4])\n",
    "reading_p_fc_bm = get_null_p(fc_bm[:,4], null_fc_bm[4])\n",
    "reading_p_fc_mf = get_null_p(fc_mf[:,4], null_fc_mf[4])\n",
    "reading_p_fc_mm = get_null_p(fc_mm[:,4], null_fc_mm[4])\n",
    "reading_p_fc_ff = get_null_p(fc_ff[:,4], null_fc_ff[4])\n",
    "reading_p_fc_fm = get_null_p(fc_fm[:,4], null_fc_fm[4])\n",
    "\n",
    "\n",
    "reading_pvals = [reading_p_fc_bf, reading_p_fc_bm, \n",
    "                 reading_p_fc_mf, reading_p_fc_mm,\n",
    "                 reading_p_fc_ff, reading_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of flanker abilities against null\n",
    "flanker_p_fc_bf = get_null_p(fc_bf[:,5], null_fc_bf[5])\n",
    "flanker_p_fc_bm = get_null_p(fc_bm[:,5], null_fc_bm[5])\n",
    "flanker_p_fc_mf = get_null_p(fc_mf[:,5], null_fc_mf[5])\n",
    "flanker_p_fc_mm = get_null_p(fc_mm[:,5], null_fc_mm[5])\n",
    "flanker_p_fc_ff = get_null_p(fc_ff[:,5], null_fc_ff[5])\n",
    "flanker_p_fc_fm = get_null_p(fc_fm[:,5], null_fc_fm[5])\n",
    "\n",
    "\n",
    "flanker_pvals = [flanker_p_fc_bf, flanker_p_fc_bm, \n",
    "                 flanker_p_fc_mf, flanker_p_fc_mm,\n",
    "                 flanker_p_fc_ff, flanker_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of cardsort abilities against null\n",
    "cardsort_p_fc_bf = get_null_p(fc_bf[:,6], null_fc_bf[6])\n",
    "cardsort_p_fc_bm = get_null_p(fc_bm[:,6], null_fc_bm[6])\n",
    "cardsort_p_fc_mf = get_null_p(fc_mf[:,6], null_fc_mf[6])\n",
    "cardsort_p_fc_mm = get_null_p(fc_mm[:,6], null_fc_mm[6])\n",
    "cardsort_p_fc_ff = get_null_p(fc_ff[:,6], null_fc_ff[6])\n",
    "cardsort_p_fc_fm = get_null_p(fc_fm[:,6], null_fc_fm[6])\n",
    "\n",
    "\n",
    "cardsort_pvals = [cardsort_p_fc_bf, cardsort_p_fc_bm, \n",
    "                 cardsort_p_fc_mf, cardsort_p_fc_mm,\n",
    "                 cardsort_p_fc_ff, cardsort_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of pic seq abilities against null\n",
    "picseq_p_fc_bf = get_null_p(fc_bf[:,7], null_fc_bf[7])\n",
    "picseq_p_fc_bm = get_null_p(fc_bm[:,7], null_fc_bm[7])\n",
    "picseq_p_fc_mf = get_null_p(fc_mf[:,7], null_fc_mf[7])\n",
    "picseq_p_fc_mm = get_null_p(fc_mm[:,7], null_fc_mm[7])\n",
    "picseq_p_fc_ff = get_null_p(fc_ff[:,7], null_fc_ff[7])\n",
    "picseq_p_fc_fm = get_null_p(fc_fm[:,7], null_fc_fm[7])\n",
    "\n",
    "\n",
    "picseq_pvals = [picseq_p_fc_bf, picseq_p_fc_bm, \n",
    "                 picseq_p_fc_mf, picseq_p_fc_mm,\n",
    "                 picseq_p_fc_ff, picseq_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of list sort abilities against null\n",
    "listsort_p_fc_bf = get_null_p(fc_bf[:,8], null_fc_bf[8])\n",
    "listsort_p_fc_bm = get_null_p(fc_bm[:,8], null_fc_bm[8])\n",
    "listsort_p_fc_mf = get_null_p(fc_mf[:,8], null_fc_mf[8])\n",
    "listsort_p_fc_mm = get_null_p(fc_mm[:,8], null_fc_mm[8])\n",
    "listsort_p_fc_ff = get_null_p(fc_ff[:,8], null_fc_ff[8])\n",
    "listsort_p_fc_fm = get_null_p(fc_fm[:,8], null_fc_fm[8])\n",
    "\n",
    "\n",
    "listsort_pvals = [listsort_p_fc_bf, listsort_p_fc_bm, \n",
    "                 listsort_p_fc_mf, listsort_p_fc_mm,\n",
    "                 listsort_p_fc_ff, listsort_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate predictions of proc speed abilities against null\n",
    "procspeed_p_fc_bf = get_null_p(fc_bf[:,9], null_fc_bf[9])\n",
    "procspeed_p_fc_bm = get_null_p(fc_bm[:,9], null_fc_bm[9])\n",
    "procspeed_p_fc_mf = get_null_p(fc_mf[:,9], null_fc_mf[9])\n",
    "procspeed_p_fc_mm = get_null_p(fc_mm[:,9], null_fc_mm[9])\n",
    "procspeed_p_fc_ff = get_null_p(fc_ff[:,9], null_fc_ff[9])\n",
    "procspeed_p_fc_fm = get_null_p(fc_fm[:,9], null_fc_fm[9])\n",
    "\n",
    "\n",
    "procspeed_pvals = [procspeed_p_fc_bf, procspeed_p_fc_bm, \n",
    "                 procspeed_p_fc_mf, procspeed_p_fc_mm,\n",
    "                 procspeed_p_fc_ff, procspeed_p_fc_fm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to highlight significant differences in tables\n",
    "def color_negative_red(val):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: red'` for negative\n",
    "    strings, black otherwise.\n",
    "    \"\"\"\n",
    "    color = 'red' if val > 0.05 else 'black'\n",
    "    return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot violin plots for all of the models\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10), sharey=True, sharex=True)\n",
    "\n",
    "#cognition = ['Crystal','Fluid','Total','PicVocab','Reading','Flanker','CardSort','PicSeq','ListSort','ProcSpeed']\n",
    "\n",
    "\n",
    "sns.violinplot(ax=axes[0,0], data=crystal)\n",
    "axes[0,0].set_title(cognition[0])\n",
    "\n",
    "sns.violinplot(ax=axes[0,1], data=fluid)\n",
    "axes[0,1].set_title(cognition[1])\n",
    "\n",
    "sns.violinplot(ax=axes[0,2], data=total)\n",
    "axes[0,2].set_title(cognition[2])\n",
    "\n",
    "sns.violinplot(ax=axes[0,3], data=picvocab)\n",
    "axes[0,3].set_title(cognition[3])\n",
    "\n",
    "sns.violinplot(ax=axes[0,4], data=reading)\n",
    "axes[0,4].set_title(cognition[4])\n",
    "\n",
    "sns.violinplot(ax=axes[1,0], data=flanker)\n",
    "axes[1,0].set_title(cognition[5])\n",
    "\n",
    "sns.violinplot(ax=axes[1,1], data=cardsort)\n",
    "axes[1,1].set_title(cognition[6])\n",
    "\n",
    "sns.violinplot(ax=axes[1,2], data=picseq)\n",
    "axes[1,2].set_title(cognition[7])\n",
    "\n",
    "sns.violinplot(ax=axes[1,3], data=listsort)\n",
    "axes[1,3].set_title(cognition[8])\n",
    "\n",
    "sns.violinplot(ax=axes[1,4], data=procspeed)\n",
    "axes[1,4].set_title(cognition[9])\n",
    "\n",
    "axes[0,0].set_ylabel('prediction accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all the pvals together for comparison against the null\n",
    "pvals = np.concatenate((crystal_pvals, fluid_pvals, total_pvals, \n",
    "                        picvocab_pvals, reading_pvals,\n",
    "                        flanker_pvals, cardsort_pvals, picseq_pvals, listsort_pvals, procspeed_pvals), axis=0)\n",
    "#correct p-vals across all models for multiple comparisons\n",
    "p_corr = fdr(pvals, alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "\n",
    "#organise data into table\n",
    "crystal_p_corr = p_corr[1][0:6]\n",
    "fluid_p_corr = p_corr[1][6:12]\n",
    "total_p_corr = p_corr[1][12:18]\n",
    "\n",
    "picvocab_p_corr = p_corr[1][18:24]\n",
    "reading_p_corr = p_corr[1][24:30]\n",
    "\n",
    "flanker_p_corr = p_corr[1][30:36]\n",
    "cardsort_p_corr = p_corr[1][36:42]\n",
    "picseq_p_corr = p_corr[1][42:48]\n",
    "listsort_p_corr = p_corr[1][48:54]\n",
    "procspeed_p_corr = p_corr[1][54:60]\n",
    "\n",
    "order = ['bf','bm','mf','mm','ff','fm']\n",
    "\n",
    "model_null_eval = pd.DataFrame({'Model' : order, \n",
    "                                'Crystal' : crystal_p_corr, \n",
    "                                'Fluid' : fluid_p_corr,\n",
    "                                'Total' : total_p_corr,\n",
    "                                'Pic Vocab' : picvocab_p_corr, \n",
    "                                'Reading' : reading_p_corr,\n",
    "                                'Flanker' : flanker_p_corr,\n",
    "                                'Card Sort' : cardsort_p_corr, \n",
    "                                'Pic Seq' : picseq_p_corr,\n",
    "                                'List Sort' : listsort_p_corr,\n",
    "                                'Proc Speed' : procspeed_p_corr}) \n",
    "\n",
    "model_null_eval = model_null_eval.set_index('Model') \n",
    "model_null_eval_sig = model_null_eval.style.applymap(color_negative_red)\n",
    "\n",
    "#show table where all models significantly better than null are shown in black, all other models in red\n",
    "model_null_eval_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['mm', 'mf', 'ff', 'fm']\n",
    "\n",
    "for i in range(len(cognition)):\n",
    "    \n",
    "    #concatenate prediction accuracy results for sex-specific models\n",
    "    corr =  [fc_mm[:,i], fc_mf[:,i],fc_ff[:,i], fc_fm[:,i]]\n",
    "    p_model_comp = np.zeros([int(len(corr)),int(len(corr))])\n",
    "\n",
    "    #check for differences usign exact test for differences\n",
    "    for k in range(len(corr)):\n",
    "         for j in range(len(corr)):\n",
    "            if k==j:\n",
    "                p_model_comp[k,j]=1\n",
    "            elif k<j:\n",
    "                p_model_comp[k,j]=1\n",
    "            else:\n",
    "                p_model_comp[k,j] = get_exact_p(corr[k],corr[j])\n",
    "\n",
    "    #correct for multiple comparions\n",
    "    p_corr = fdr(p_model_comp, alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "    \n",
    "    #organise into table\n",
    "    model_comp = pd.DataFrame({'Model' : order, \n",
    "                           'mf' : p_model_comp[:,0],\n",
    "                           'mm' : p_model_comp[:,1],\n",
    "                           'ff' : p_model_comp[:,2],\n",
    "                           'fm' : p_model_comp[:,3]})\n",
    "\n",
    "    model_comp = model_comp.set_index('Model') \n",
    "    print(cognition[i])\n",
    "    print(model_comp)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
