{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import sys; sys.path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "#import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in functional connectivity data + subj data file\n",
    "fc = pd.read_csv('fc.csv', header=None).values\n",
    "T = pd.read_csv('subj_data.csv',header=0)\n",
    "\n",
    "#names of specific cognitive metrics you want to evaluate\n",
    "cognition = ['Crystal','Fluid','Total','PicVocab','Reading','Flanker','CardSort','PicSeq','ListSort','ProcSpeed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the specific cognitive metrics\n",
    "crystal = T.CogCrystalComp_AgeAdj.values\n",
    "fluid = T.CogFluidComp_AgeAdj.values\n",
    "total = T.CogTotalComp_AgeAdj.values\n",
    "picvocab = T.PicVocab_AgeAdj.values\n",
    "reading = T.ReadEng_AgeAdj.values\n",
    "flanker = T.Flanker_AgeAdj.values\n",
    "cardsort = T.CardSort_AgeAdj.values\n",
    "picseq = T.PicSeq_AgeAdj.values\n",
    "listsort = T.ListSort_AgeAdj.values\n",
    "procspeed = T.ProcSpeed_AgeAdj.values\n",
    "\n",
    "#put them all into one array\n",
    "cog_metric = np.transpose(np.asarray([crystal, fluid, total, picvocab, reading, flanker, cardsort, picseq, listsort, procspeed]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the # of cv loops and # of test loops and test size and number of cog variables to predict\n",
    "perm = 100\n",
    "cv_loops = 5\n",
    "k = 3\n",
    "train_size = .8\n",
    "n_cog = np.size(cognition)\n",
    "\n",
    "#set train data for males and females depending on what you want the input variable to be\n",
    "X = fc\n",
    "\n",
    "X_m = fc[T.Gender=='M',:]\n",
    "Y_m = cog_metric[T.Gender=='M',:]\n",
    "\n",
    "X_f = fc[T.Gender=='F',:]\n",
    "Y_f = cog_metric[T.Gender=='F',:]\n",
    "\n",
    "#set the number of features \n",
    "n_feat = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featimp_m[:,:,0] = pd.read_csv('crystal_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,0] = pd.read_csv('crystal_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,0] = pd.read_csv('crystal_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,1] = pd.read_csv('fluid_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,1] = pd.read_csv('fluid_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,1] = pd.read_csv('fluid_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,2] = pd.read_csv('total_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,2] = pd.read_csv('total_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,2] = pd.read_csv('total_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,3] = pd.read_csv('picvocab_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,3] = pd.read_csv('picvocab_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,3] = pd.read_csv('picvocab_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,4] = pd.read_csv('reading_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,4] = pd.read_csv('reading_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,4] = pd.read_csv('reading_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,5] = pd.read_csv('flanker_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,5] = pd.read_csv('flanker_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,5] = pd.read_csv('flanker_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,6] = pd.read_csv('cardsort_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,6] = pd.read_csv('cardsort_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,6] = pd.read_csv('cardsort_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,7] = pd.read_csv('picseq_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,7] = pd.read_csv('picseq_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,7] = pd.read_csv('picseq_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,8] = pd.read_csv('listsort_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,8] = pd.read_csv('listsort_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,8] = pd.read_csv('listsort_featimp_b.txt',header=None).values\n",
    "\n",
    "featimp_m[:,:,9] = pd.read_csv('procspeed_featimp_m.txt',header=None).values\n",
    "featimp_f[:,:,9] = pd.read_csv('procspeed_featimp_f.txt',header=None).values\n",
    "featimp_b[:,:,9] = pd.read_csv('procspeed_featimp_b.txt',header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through permutations\n",
    "for p in range(perm):\n",
    "    print('Permutation %d' %(p+1))\n",
    "\n",
    "    cov_x_b = np.zeros([n_feat])\n",
    "    cov_x_m = np.zeros([n_feat])\n",
    "    cov_x_f = np.zeros([n_feat])\n",
    "    \n",
    "    x_train_m, x_test_m, cog_train_m, cog_test_m = train_test_split(X_m, Y_m, test_size=1-train_size, shuffle=True, random_state=p)\n",
    "    x_train_f, x_test_f, cog_train_f, cog_test_f = train_test_split(X_f, Y_f, test_size=1-train_size, shuffle=True, random_state=p)\n",
    "\n",
    "    \n",
    "    x_train_b = np.concatenate((x_train_m, x_train_f), axis=0)\n",
    "    cog_train_b = np.concatenate((cog_train_m, cog_train_f), axis=0)\n",
    "    \n",
    "    #compute covariance of training X data\n",
    "    cov_x_b = np.cov(np.transpose(x_train_b))\n",
    "    cov_x_m = np.cov(np.transpose(x_train_m))\n",
    "    cov_x_f = np.cov(np.transpose(x_train_f))\n",
    "\n",
    "    #for each of the cognitive scores\n",
    "    for i in range(n_cog):\n",
    "        #compute covariance of training cognitive scores\n",
    "        cov_y_b = np.cov(cog_train_b[:,i])\n",
    "        cov_y_m = np.cov(cog_train_m[:,i])\n",
    "        cov_y_f = np.cov(cog_train_f[:,i])\n",
    "        \n",
    "        #compute activation vector by matrix multiplying training X covariance, feature weights, and 1/training Y covariance \n",
    "        A_b[p,:,i] = np.matmul(cov_x_b,featimp_b[p,:,i])*(1/cov_y_b)\n",
    "        A_m[p,:,i] = np.matmul(cov_x_m,featimp_m[p,:,i])*(1/cov_y_m)\n",
    "        A_f[p,:,i] = np.matmul(cov_x_f,featimp_f[p,:,i])*(1/cov_y_f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "np.savetxt('fc_392_coco439_crystal_A_m.txt', A_m[:,:,0], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_crystal_A_f.txt', A_f[:,:,0], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_fluid_A_m.txt', A_m[:,:,1], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_fluid_A_f.txt', A_f[:,:,1], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_total_A_m.txt', A_m[:,:,2], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_total_A_f.txt', A_f[:,:,2], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_picvocab_A_m.txt', A_m[:,:,3], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_picvocab_A_f.txt', A_f[:,:,3], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_reading_A_m.txt', A_m[:,:,4], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_reading_A_f.txt', A_f[:,:,4], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_flanker_A_m.txt', A_m[:,:,5], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_flanker_A_f.txt', A_f[:,:,5], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_cardsort_A_m.txt', A_m[:,:,6], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_cardsort_A_f.txt', A_f[:,:,6], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_picseq_A_m.txt', A_m[:,:,7], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_picseq_A_f.txt', A_f[:,:,7], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_listsort_A_m.txt', A_m[:,:,8], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_listsort_A_f.txt', A_f[:,:,8], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_procspeed_A_m.txt', A_m[:,:,9], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_procspeed_A_f.txt', A_f[:,:,9], delimiter=',')\n",
    "\n",
    "np.savetxt('fc_392_coco439_crystal_A_b.txt', A_b[:,:,0], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_fluid_A_b.txt', A_b[:,:,1], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_total_A_b.txt', A_b[:,:,2], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_picvocab_A_b.txt', A_b[:,:,3], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_reading_A_b.txt', A_b[:,:,4], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_flanker_A_b.txt', A_b[:,:,5], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_cardsort_A_b.txt', A_b[:,:,6], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_picseq_A_b.txt', A_b[:,:,7], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_listsort_A_b.txt', A_b[:,:,8], delimiter=',')\n",
    "np.savetxt('fc_392_coco439_procspeed_A_b.txt', A_b[:,:,9], delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute and save mean across 100 iterations\n",
    "A_m_avg = np.mean(A_m,axis=0)\n",
    "A_f_avg = np.mean(A_f,axis=0)\n",
    "A_b_avg = np.mean(A_b,axis=0)\n",
    "\n",
    "\n",
    "np.savetxt('fc_392_coco439_A_b_avg.txt', A_b_avg, delimiter=',')\n",
    "np.savetxt('fc_392_coco439_A_m_avg.txt', A_m_avg, delimiter=',')\n",
    "np.savetxt('fc_392_coco439_A_f_avg.txt', A_f_avg, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
