{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import sys; sys.path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "#import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in functional connectivity data + subj data file\n",
    "fc = pd.read_csv('fc.csv', header=None).values\n",
    "T = pd.read_csv('subj_data.csv',header=0)\n",
    "\n",
    "#names of specific cognitive metrics you want to evaluate\n",
    "cognition = ['Crystal','Fluid','Total','PicVocab','Reading','Flanker','CardSort','PicSeq','ListSort','ProcSpeed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the specific cognitive metrics\n",
    "crystal = T.CogCrystalComp_AgeAdj.values\n",
    "fluid = T.CogFluidComp_AgeAdj.values\n",
    "total = T.CogTotalComp_AgeAdj.values\n",
    "picvocab = T.PicVocab_AgeAdj.values\n",
    "reading = T.ReadEng_AgeAdj.values\n",
    "flanker = T.Flanker_AgeAdj.values\n",
    "cardsort = T.CardSort_AgeAdj.values\n",
    "picseq = T.PicSeq_AgeAdj.values\n",
    "listsort = T.ListSort_AgeAdj.values\n",
    "procspeed = T.ProcSpeed_AgeAdj.values\n",
    "\n",
    "#put them all into one array\n",
    "cog_metric = np.transpose(np.asarray([crystal, fluid, total, picvocab, reading, flanker, cardsort, picseq, listsort, procspeed]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the # of cv loops and # of test loops and test size and number of cog variables to predict\n",
    "perm = 100\n",
    "cv_loops = 5\n",
    "k = 3\n",
    "train_size = .8\n",
    "n_cog = np.size(cognition)\n",
    "\n",
    "#set regression model type, and hyperparameter grid to search\n",
    "regr = Ridge(normalize=True, max_iter=1000000)\n",
    "alphas = np.linspace(250, 1000, num=4, endpoint=True, dtype=None)\n",
    "paramGrid ={'alpha': alphas}\n",
    "\n",
    "#set train data for males and females depending on what you want the input variable to be\n",
    "X = fc\n",
    "\n",
    "X_m = fc[T.Gender=='M',:]\n",
    "Y_m = cog_metric[T.Gender=='M',:]\n",
    "\n",
    "X_f = fc[T.Gender=='F',:]\n",
    "Y_f = cog_metric[T.Gender=='F',:]\n",
    "\n",
    "#set the number of features \n",
    "n_feat = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create arrays to store coefficient of determination from different models\n",
    "#bb indicates trained on both, tested on both (sex-independent model)\n",
    "r2_bb = np.zeros([perm,n_cog])\n",
    "\n",
    "#bm indicates trained on male, tested on male (sex-independent model)\n",
    "r2_bm = np.zeros([perm,n_cog])\n",
    "\n",
    "#bf indicates trained on male, tested on female (sex-independent model)\n",
    "r2_bf = np.zeros([perm,n_cog])\n",
    "\n",
    "#mm indicates trained on male, tested on male (male-specific model)\n",
    "r2_mm = np.zeros([perm,n_cog])\n",
    "\n",
    "#mf indicates trained on male, tested on female (male-specific model)\n",
    "r2_mf = np.zeros([perm,n_cog])\n",
    "\n",
    "#ff indicates trained on female, tested on female (female-specific model)\n",
    "r2_ff = np.zeros([perm,n_cog])\n",
    "\n",
    "#fm indicates trained on female, tested on male (female-specific model)\n",
    "r2_fm = np.zeros([perm,n_cog])\n",
    "\n",
    "#create variables to store explained variance\n",
    "var_bb = np.zeros([perm,n_cog])\n",
    "var_bm = np.zeros([perm,n_cog])\n",
    "var_bf = np.zeros([perm,n_cog])\n",
    "var_mm = np.zeros([perm,n_cog])\n",
    "var_mf = np.zeros([perm,n_cog])\n",
    "var_ff = np.zeros([perm,n_cog])\n",
    "var_fm = np.zeros([perm,n_cog])\n",
    "\n",
    "#create variables to store prediction accuracy\n",
    "corr_bb = np.zeros([perm,n_cog])\n",
    "corr_bm = np.zeros([perm,n_cog])\n",
    "corr_bf = np.zeros([perm,n_cog])\n",
    "corr_mm = np.zeros([perm,n_cog])\n",
    "corr_mf = np.zeros([perm,n_cog])\n",
    "corr_ff = np.zeros([perm,n_cog])\n",
    "corr_fm = np.zeros([perm,n_cog])\n",
    "\n",
    "#create variables to store optimised hyperparameters\n",
    "opt_alpha_b = np.zeros([perm,n_cog])\n",
    "opt_alpha_m = np.zeros([perm,n_cog])\n",
    "opt_alpha_f = np.zeros([perm,n_cog])\n",
    "\n",
    "#create variables to store output variables for test set\n",
    "cogtest_m = np.zeros([perm,n_cog,int(np.ceil(X_m.shape[0]*(1-train_size)))])\n",
    "cogtest_f = np.zeros([perm,n_cog,int(np.ceil(X_f.shape[0]*(1-train_size)))])\n",
    "cogtest_b = np.zeros([perm,n_cog,cogtest_m.shape[2]+cogtest_f.shape[2]])\n",
    "\n",
    "#create variabels to store predictions from the models\n",
    "preds_mm = np.zeros([perm,n_cog,int(np.ceil(X_m.shape[0]*(1-train_size)))])\n",
    "preds_mf = np.zeros([perm,n_cog,int(np.ceil(X_f.shape[0]*(1-train_size)))])\n",
    "preds_ff = np.zeros([perm,n_cog,int(np.ceil(X_f.shape[0]*(1-train_size)))])\n",
    "preds_fm = np.zeros([perm,n_cog,int(np.ceil(X_m.shape[0]*(1-train_size)))])\n",
    "preds_bb = np.zeros([perm,n_cog,cogtest_m.shape[2]+cogtest_f.shape[2]])\n",
    "preds_bm = np.zeros([perm,n_cog,int(np.ceil(X_m.shape[0]*(1-train_size)))])\n",
    "preds_bf = np.zeros([perm,n_cog,int(np.ceil(X_f.shape[0]*(1-train_size)))])\n",
    "\n",
    "#create variables to store feature importance\n",
    "featimp_b = np.zeros([perm,n_feat,n_cog])\n",
    "featimp_m = np.zeros([perm,n_feat,n_cog])\n",
    "featimp_f = np.zeros([perm,n_feat,n_cog])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise and Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterate through permutations\n",
    "for p in range(perm):\n",
    "    print('Permutation %d' %(p+1))\n",
    "    \n",
    "    #split male and female data into train and test splits\n",
    "    x_train_m, x_test_m, cog_train_m, cog_test_m = train_test_split(X_m, Y_m, test_size=1-train_size, shuffle=True, random_state=p)\n",
    "    x_train_f, x_test_f, cog_train_f, cog_test_f = train_test_split(X_f, Y_f, test_size=1-train_size, shuffle=True, random_state=p)\n",
    "    \n",
    "    #concatenate train and test data across the sexes for sex-independent model\n",
    "    x_train_b = np.concatenate((x_train_m, x_train_f), axis=0)\n",
    "    x_test_b = np.concatenate((x_test_m, x_test_f), axis=0)\n",
    "    \n",
    "    cog_train_b = np.concatenate((cog_train_m, cog_train_f), axis=0)\n",
    "    cog_test_b = np.concatenate((cog_test_m, cog_test_f), axis=0)\n",
    "    \n",
    "    #iterate through the cognitive metrics to predict\n",
    "    for cog in range (n_cog):\n",
    "\n",
    "        #print cognitive metrics being predicted \n",
    "        print (\"Cognition: %s\" % cognition[cog])\n",
    "        \n",
    "        #set y values for train and test sets for sex-independent and sex-specific models     \n",
    "        y_train_b = cog_train_b[:,cog]\n",
    "        y_train_m = cog_train_m[:,cog]\n",
    "        y_train_f = cog_train_f[:,cog]\n",
    "    \n",
    "        y_test_b = cog_test_b[:,cog]\n",
    "        y_test_m = cog_test_m[:,cog]\n",
    "        y_test_f = cog_test_f[:,cog]\n",
    "        \n",
    "        #save test data\n",
    "        cogtest_b[p,cog,:] = y_test_b\n",
    "        cogtest_m[p,cog,:] = y_test_m\n",
    "        cogtest_f[p,cog,:] = y_test_f\n",
    "\n",
    "        #set variables to store nested CV scores, and best parameters from hyperparameter optimisation\n",
    "        nested_scores_b = []\n",
    "        best_params_b = []\n",
    "        \n",
    "        nested_scores_m = []\n",
    "        best_params_m = []\n",
    "\n",
    "        nested_scores_f = []\n",
    "        best_params_f = []\n",
    "        \n",
    "\n",
    "        #optimise regression model using nested CV\n",
    "        print('Training Models')\n",
    "        \n",
    "          \n",
    "        for i in range(cv_loops):\n",
    "\n",
    "            #print(\"Nested CV - %d/%d\" % (i,cv_loops))\n",
    "\n",
    "            #set parameters for inner and outer loops for CV\n",
    "            inner_cv = KFold(n_splits=k, shuffle=True, random_state=i)\n",
    "            outer_cv = KFold(n_splits=k, shuffle=True, random_state=i)\n",
    "            \n",
    "            #SEX-INDEPENDENT MODEL\n",
    "            #define regressor with grid-search CV for inner loop\n",
    "            gridSearch_b = GridSearchCV(estimator=regr, param_grid=paramGrid, n_jobs=-1,\n",
    "                                      verbose=0, cv=inner_cv, scoring='r2')\n",
    "\n",
    "            #fit regression\n",
    "            gridSearch_b.fit(x_train_b, y_train_b)\n",
    "\n",
    "            #save parameters corresponding to the best score\n",
    "            best_params_b.append(list(gridSearch_b.best_params_.values()))\n",
    "\n",
    "            #call cross_val_score for outer loop\n",
    "            nested_score_b = cross_val_score(gridSearch_b, X=x_train_b, y=y_train_b, cv=outer_cv, \n",
    "                                           scoring='r2', verbose=1)\n",
    "\n",
    "            #record nested CV scores\n",
    "            nested_scores_b.append(np.median(nested_score_b))\n",
    "\n",
    "            \n",
    "            #MALE-SPECIFIC MODEL\n",
    "            #define regressor with grid-search CV for inner loop\n",
    "            gridSearch_m = GridSearchCV(estimator=regr, param_grid=paramGrid, n_jobs=-1, \n",
    "                                      verbose=0, cv=inner_cv, scoring='r2')\n",
    "\n",
    "            #fit regression\n",
    "            gridSearch_m.fit(x_train_m, y_train_m)\n",
    "\n",
    "            #save parameters corresponding to the best score\n",
    "            best_params_m.append(list(gridSearch_m.best_params_.values()))\n",
    "\n",
    "            #call cross_val_score for outer loop\n",
    "            nested_score_m = cross_val_score(gridSearch_m, X=x_train_m, y=y_train_m, cv=outer_cv, \n",
    "                                           scoring='r2', verbose=1)\n",
    "\n",
    "            #record nested CV scores\n",
    "            nested_scores_m.append(np.median(nested_score_m))\n",
    "\n",
    "\n",
    "            #FEMALE-SPECIFIC MODEL\n",
    "            #define regressor with grid-search CV for inner loop\n",
    "            gridSearch_f = GridSearchCV(estimator=regr, param_grid=paramGrid, n_jobs=-1, \n",
    "                                      verbose=0, cv=inner_cv)\n",
    "\n",
    "            #fit regression\n",
    "            gridSearch_f.fit(x_train_f, y_train_f)\n",
    "\n",
    "            #save parameters corresponding to the best score\n",
    "            best_params_f.append(list(gridSearch_f.best_params_.values()))\n",
    "\n",
    "            #call cross_val_score for outer loop\n",
    "            nested_score_f = cross_val_score(gridSearch_f, X=x_train_f, y=y_train_f, cv=outer_cv, \n",
    "                                           scoring='r2', verbose=1)\n",
    "\n",
    "            #record nested CV scores\n",
    "            nested_scores_f.append(np.median(nested_score_f))\n",
    "            \n",
    "            print(\"%d/%d Complete\" % (i+1,cv_loops))\n",
    "            \n",
    "            \n",
    "        print('Testing Models')\n",
    "\n",
    "        #once all CV loops are complete, fit models based on optimised hyperparameters\n",
    "\n",
    "        #save optimised alpha values\n",
    "        opt_alpha_b[p,cog] = np.median(best_params_b)\n",
    "        opt_alpha_m[p,cog] = np.median(best_params_m)\n",
    "        opt_alpha_f[p,cog] = np.median(best_params_f)\n",
    "\n",
    "\n",
    "        #fit sex-independent model\n",
    "        model_b = Ridge(alpha = opt_alpha_b[p,cog], normalize=True, max_iter=1000000)\n",
    "        model_b.fit(x_train_b, y_train_b);\n",
    "        \n",
    "        #fit sex-specific models\n",
    "        model_m = Ridge(alpha = opt_alpha_m[p,cog], normalize=True, max_iter=1000000)\n",
    "        model_m.fit(x_train_m, y_train_m);\n",
    "\n",
    "        model_f = Ridge(alpha = opt_alpha_f[p,cog], normalize=True, max_iter=1000000)\n",
    "        model_f.fit(x_train_f, y_train_f);\n",
    "\n",
    "        #evaluate sex-independent model when testing on both sexes, testing on males, and testing on females\n",
    "        r2_bb[p,cog]=model_b.score(x_test_b,y_test_b)\n",
    "        r2_bm[p,cog]=model_b.score(x_test_m,y_test_m)\n",
    "        r2_bf[p,cog]=model_b.score(x_test_f,y_test_f)\n",
    "        \n",
    "        #evaluate sex-specific models when testing on males, and testing on females\n",
    "        r2_mm[p,cog]=model_m.score(x_test_m,y_test_m)\n",
    "        r2_mf[p,cog]=model_m.score(x_test_f,y_test_f)\n",
    "\n",
    "        r2_fm[p,cog]=model_f.score(x_test_m,y_test_m)\n",
    "        r2_ff[p,cog]=model_f.score(x_test_f,y_test_f)\n",
    "\n",
    "\n",
    "        #generate predictions from sex-independent model\n",
    "        preds_bb[p,cog,:] = model_b.predict(x_test_b).ravel()\n",
    "        preds_bm[p,cog,:] = model_b.predict(x_test_m).ravel()\n",
    "        preds_bf[p,cog,:] = model_b.predict(x_test_f).ravel()\n",
    "        \n",
    "        #generate predictions from male-specific model\n",
    "        preds_mm[p,cog,:] = model_m.predict(x_test_m).ravel()\n",
    "        preds_mf[p,cog,:] = model_m.predict(x_test_f).ravel()\n",
    "\n",
    "        #generate predictions from female-specifc model\n",
    "        preds_ff[p,cog,:] = model_f.predict(x_test_f).ravel()\n",
    "        preds_fm[p,cog,:] = model_f.predict(x_test_m).ravel()\n",
    "\n",
    "        \n",
    "        #compute explained variance from sex-independent model\n",
    "        var_bb[p,cog] = explained_variance_score(y_test_b, preds_bb[p,cog,:])\n",
    "        var_bm[p,cog] = explained_variance_score(y_test_m, preds_bm[p,cog,:])\n",
    "        var_bf[p,cog] = explained_variance_score(y_test_f, preds_bf[p,cog,:])\n",
    "        \n",
    "        #compute explained variance from male-specific model\n",
    "        var_mm[p,cog] = explained_variance_score(y_test_m, preds_mm[p,cog,:])\n",
    "        var_mf[p,cog] = explained_variance_score(y_test_f, preds_mf[p,cog,:])\n",
    "\n",
    "        #compute explained variance from male-specific model\n",
    "        var_ff[p,cog] = explained_variance_score(y_test_f, preds_ff[p,cog,:])\n",
    "        var_fm[p,cog] = explained_variance_score(y_test_m, preds_fm[p,cog,:])\n",
    "\n",
    "\n",
    "        #compute prediciton accuracy from sex-independent model\n",
    "        corr_bb[p,cog] = np.corrcoef(y_test_b, preds_bb[p,cog,:])[1,0]\n",
    "        corr_bm[p,cog] = np.corrcoef(y_test_m, preds_bm[p,cog,:])[1,0]\n",
    "        corr_bf[p,cog] = np.corrcoef(y_test_f, preds_bf[p,cog,:])[1,0]\n",
    "        \n",
    "        #compute prediciton accuracy from male-specific model\n",
    "        corr_mm[p,cog] = np.corrcoef(y_test_m, preds_mm[p,cog,:])[1,0]\n",
    "        corr_mf[p,cog] = np.corrcoef(y_test_f, preds_mf[p,cog,:])[1,0]\n",
    "        \n",
    "        #compute prediciton accuracy from female-specific model\n",
    "        corr_ff[p,cog] = np.corrcoef(y_test_f, preds_ff[p,cog,:])[1,0]\n",
    "        corr_fm[p,cog] = np.corrcoef(y_test_m, preds_fm[p,cog,:])[1,0]\n",
    "\n",
    "\n",
    "        #extract feature importance from all models        \n",
    "        featimp_b[p,:,cog] = model_b.coef_\n",
    "        featimp_m[p,:,cog] = model_m.coef_\n",
    "        featimp_f[p,:,cog] = model_f.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save r2 (coefficient of determination)\n",
    "np.savetxt('r2_bm.txt', r2_bm, delimiter=',')\n",
    "np.savetxt('r2_bf.txt', r2_bf, delimiter=',')\n",
    "np.savetxt('r2_mm.txt', r2_mm, delimiter=',')\n",
    "np.savetxt('r2_mf.txt', r2_mf, delimiter=',')\n",
    "np.savetxt('r2_fm.txt', r2_fm, delimiter=',')\n",
    "np.savetxt('r2_ff.txt', r2_ff, delimiter=',')\n",
    "\n",
    "\n",
    "#save explained variance\n",
    "np.savetxt('var_bm.txt', var_bm, delimiter=',')\n",
    "np.savetxt('var_bf.txt', var_bf, delimiter=',')\n",
    "np.savetxt('var_mm.txt', var_mm, delimiter=',')\n",
    "np.savetxt('var_mf.txt', var_mf, delimiter=',')\n",
    "np.savetxt('var_fm.txt', var_fm, delimiter=',')\n",
    "np.savetxt('var_ff.txt', var_ff, delimiter=',')\n",
    "\n",
    "\n",
    "#save prediction accuracy\n",
    "np.savetxt('corr_bm.txt', corr_bm, delimiter=',')\n",
    "np.savetxt('corr_bf.txt', corr_bf, delimiter=',')\n",
    "np.savetxt('corr_mm.txt', corr_mm, delimiter=',')\n",
    "np.savetxt('corr_mf.txt', corr_mf, delimiter=',')\n",
    "np.savetxt('corr_fm.txt', corr_fm, delimiter=',')\n",
    "np.savetxt('corr_ff.txt', corr_ff, delimiter=',')\n",
    "\n",
    "#save optimised hyperparameters\n",
    "np.savetxt('alpha_b.txt', opt_alpha_b, delimiter=',')\n",
    "np.savetxt('alpha_m.txt', opt_alpha_m, delimiter=',')\n",
    "np.savetxt('alpha_f.txt', opt_alpha_f, delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "#save feature importances\n",
    "np.savetxt('crystal_featimp_b.txt', featimp_b[:,:,0], delimiter=',')\n",
    "np.savetxt('crystal_featimp_m.txt', featimp_m[:,:,0], delimiter=',')\n",
    "np.savetxt('crystal_featimp_f.txt', featimp_f[:,:,0], delimiter=',')\n",
    "\n",
    "np.savetxt('fluid_featimp_b.txt', featimp_b[:,:,1], delimiter=',')\n",
    "np.savetxt('fluid_featimp_m.txt', featimp_m[:,:,1], delimiter=',')\n",
    "np.savetxt('fluid_featimp_f.txt', featimp_f[:,:,1], delimiter=',')\n",
    "\n",
    "np.savetxt('total_featimp_b.txt', featimp_b[:,:,2], delimiter=',')\n",
    "np.savetxt('total_featimp_m.txt', featimp_m[:,:,2], delimiter=',')\n",
    "np.savetxt('total_featimp_f.txt', featimp_f[:,:,2], delimiter=',')\n",
    "\n",
    "np.savetxt('picvocab_featimp_b.txt', featimp_b[:,:,3], delimiter=',')\n",
    "np.savetxt('picvocab_featimp_m.txt', featimp_m[:,:,3], delimiter=',')\n",
    "np.savetxt('picvocab_featimp_f.txt', featimp_f[:,:,3], delimiter=',')\n",
    "\n",
    "np.savetxt('reading_featimp_b.txt', featimp_b[:,:,4], delimiter=',')\n",
    "np.savetxt('reading_featimp_m.txt', featimp_m[:,:,4], delimiter=',')\n",
    "np.savetxt('reading_featimp_f.txt', featimp_f[:,:,4], delimiter=',')\n",
    "\n",
    "np.savetxt('flanker_featimp_b.txt', featimp_b[:,:,5], delimiter=',')\n",
    "np.savetxt('flanker_featimp_m.txt', featimp_m[:,:,5], delimiter=',')\n",
    "np.savetxt('flanker_featimp_f.txt', featimp_f[:,:,5], delimiter=',')\n",
    "\n",
    "np.savetxt('cardsort_featimp_b.txt', featimp_b[:,:,6], delimiter=',')\n",
    "np.savetxt('cardsort_featimp_m.txt', featimp_m[:,:,6], delimiter=',')\n",
    "np.savetxt('cardsort_featimp_f.txt', featimp_f[:,:,6], delimiter=',')\n",
    "\n",
    "np.savetxt('picseq_featimp_b.txt', featimp_b[:,:,7], delimiter=',')\n",
    "np.savetxt('picseq_featimp_m.txt', featimp_m[:,:,7], delimiter=',')\n",
    "np.savetxt('picseq_featimp_f.txt', featimp_f[:,:,7], delimiter=',')\n",
    "\n",
    "np.savetxt('listsort_featimp_b.txt', featimp_b[:,:,8], delimiter=',')\n",
    "np.savetxt('listsort_featimp_m.txt', featimp_m[:,:,8], delimiter=',')\n",
    "np.savetxt('listsort_featimp_f.txt', featimp_f[:,:,8], delimiter=',')\n",
    "\n",
    "np.savetxt('procspeed_featimp_b.txt', featimp_b[:,:,9], delimiter=',')\n",
    "np.savetxt('procspeed_featimp_m.txt', featimp_m[:,:,9], delimiter=',')\n",
    "np.savetxt('procspeed_featimp_f.txt', featimp_f[:,:,9], delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
